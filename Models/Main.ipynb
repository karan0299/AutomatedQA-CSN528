{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# from qa_model import Model\n",
    "%run Model.py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "########################################################################################\n",
    "embedding_size = 50\n",
    "mode = \"train\"\n",
    "\n",
    "num_epochs = 0\n",
    "learning_rate = 0.001\n",
    "max_gradient_norm = 5.0\n",
    "dropout = 0.15\n",
    "batch_size = 60\n",
    "hidden_size_encoder = 150\n",
    "hidden_size_qp_matching = 150\n",
    "hidden_size_sm_matching = 50\n",
    "hidden_size_fully_connected = 200\n",
    "context_len = 300\n",
    "question_len = 30\n",
    "embedding_size = 100\n",
    "\n",
    "########################################################################################\n",
    "data_dir = \"../Data/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "def initialize_model(session, model, train_dir, expect_exists):\n",
    "    \"\"\"\n",
    "    Initializes model from train_dir.\n",
    "\n",
    "    Inputs:\n",
    "      session: TensorFlow session\n",
    "      model: QAModel\n",
    "      train_dir: path to directory where we'll look for checkpoint\n",
    "      expect_exists: If True, throw an error if no checkpoint is found.\n",
    "        If False, initialize fresh model if no checkpoint is found.\n",
    "    \"\"\"\n",
    "    print(\"Looking for model at %s...\" % train_dir)\n",
    "    ckpt = tf.train.get_checkpoint_state(train_dir)\n",
    "    v2_path = ckpt.model_checkpoint_path + \".index\" if ckpt else \"\"\n",
    "    if ckpt and (tf.gfile.Exists(ckpt.model_checkpoint_path) or tf.gfile.Exists(v2_path)):\n",
    "        print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path_)\n",
    "        model.saver.restore(session, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        if expect_exists:\n",
    "            raise Exception(\"There is no saved checkpoint at %s\" % train_dir)\n",
    "        else:\n",
    "            print(\"There is no saved checkpoint at %s. Creating model with fresh parameters.\" % train_dir)\n",
    "            session.run(tf.global_variables_initializer())\n",
    "            print('Num params: %d' % sum(v.get_shape().num_elements() for v in tf.trainable_variables()))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "_PAD = b\"<pad>\"\n",
    "_UNK = b\"<unk>\"\n",
    "_START_VOCAB = [_PAD, _UNK]\n",
    "PAD_ID = 0\n",
    "UNK_ID = 1\n",
    "\n",
    "def get_glove(glove_path, glove_dim):\n",
    "    \"\"\"Reads from original GloVe .txt file and returns embedding matrix and\n",
    "    mappings from words to word ids.\n",
    "\n",
    "    Input:\n",
    "      glove_path: path to glove.6B.{glove_dim}d.txt\n",
    "      glove_dim: integer; needs to match the dimension in glove_path\n",
    "\n",
    "    Returns:\n",
    "      emb_matrix: Numpy array shape (400002, glove_dim) containing glove embeddings\n",
    "        (plus PAD and UNK embeddings in first two rows).\n",
    "        The rows of emb_matrix correspond to the word ids given in word2id and id2word\n",
    "      word2id: dictionary mapping word (string) to word id (int)\n",
    "      id2word: dictionary mapping word id (int) to word (string)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Loading GLoVE vectors from file: %s\" % glove_path)\n",
    "    vocab_size = int(4e5) # this is the vocab size of the corpus we've downloaded\n",
    "\n",
    "    emb_matrix = np.zeros((vocab_size + len(_START_VOCAB), glove_dim))\n",
    "    word2id = {}\n",
    "    id2word = {}\n",
    "\n",
    "    random_init = True\n",
    "    # randomly initialize the special tokens\n",
    "    if random_init:\n",
    "        emb_matrix[:len(_START_VOCAB), :] = np.random.randn(len(_START_VOCAB), glove_dim)\n",
    "\n",
    "    # put start tokens in the dictionaries\n",
    "    idx = 0\n",
    "    for word in _START_VOCAB:\n",
    "        word2id[word] = idx\n",
    "        id2word[idx] = word\n",
    "        idx += 1\n",
    "\n",
    "    # go through glove vecs\n",
    "    with open(glove_path, 'r') as fh:\n",
    "        for line in tqdm(fh, total=vocab_size):\n",
    "            line = line.lstrip().rstrip().split(\" \")\n",
    "            word = line[0]\n",
    "            vector = list(map(float, line[1:]))\n",
    "            if glove_dim != len(vector):\n",
    "                raise Exception(\"You set --glove_path=%s but --embedding_size=%i. If you set --glove_path yourself then make sure that --embedding_size matches!\" % (glove_path, glove_dim))\n",
    "            emb_matrix[idx, :] = vector\n",
    "            word2id[word] = idx\n",
    "            id2word[idx] = word\n",
    "            idx += 1\n",
    "\n",
    "    final_vocab_size = vocab_size + len(_START_VOCAB)\n",
    "    assert len(word2id) == final_vocab_size\n",
    "    assert len(id2word) == final_vocab_size\n",
    "    assert idx == final_vocab_size\n",
    "\n",
    "    return emb_matrix, word2id, id2word\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "def initialize_model(session, model, train_dir, expect_exists):\n",
    "    \"\"\"\n",
    "    Initializes model from train_dir.\n",
    "\n",
    "    Inputs:\n",
    "      session: TensorFlow session\n",
    "      model: QAModel\n",
    "      train_dir: path to directory where we'll look for checkpoint\n",
    "      expect_exists: If True, throw an error if no checkpoint is found.\n",
    "        If False, initialize fresh model if no checkpoint is found.\n",
    "    \"\"\"\n",
    "    print(\"Looking for model at %s...\" % train_dir)\n",
    "    ckpt = tf.train.get_checkpoint_state(train_dir)\n",
    "    v2_path = ckpt.model_checkpoint_path + \".index\" if ckpt else \"\"\n",
    "    if ckpt and (tf.gfile.Exists(ckpt.model_checkpoint_path) or tf.gfile.Exists(v2_path)):\n",
    "        print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path_)\n",
    "        model.saver.restore(session, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        if expect_exists:\n",
    "            raise Exception(\"There is no saved checkpoint at %s\" % train_dir)\n",
    "        else:\n",
    "            print(\"There is no saved checkpoint at %s. Creating model with fresh parameters.\" % train_dir)\n",
    "            session.run(tf.global_variables_initializer())\n",
    "            print('Num params: %d' % sum(v.get_shape().num_elements() for v in tf.trainable_variables()))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "glove_path = data_dir + \"Glove/\" + \"glove.6B.{}d.txt\".format(embedding_size)\n",
    "# Load embedding matrix and vocab mappings\n",
    "emb_matrix, word2id, id2word = get_glove(glove_path, embedding_size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading GLoVE vectors from file: ../Data/Glove/glove.6B.50d.txt\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 400000/400000 [00:07<00:00, 55379.10it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "# Get filepaths to train/dev datafiles for tokenized queries, contexts and answers\n",
    "train_context_path = data_dir + \"Train/\" + \"context\"\n",
    "train_qn_path = data_dir + \"Train/\" + \"question\"\n",
    "train_ans_path = data_dir + \"Train/\" + \"span\"\n",
    "\n",
    "dev_context_path = data_dir + \"Dev/\" + \"context\"\n",
    "dev_qn_path = data_dir + \"Dev/\" + \"question\"\n",
    "dev_ans_path = data_dir + \"Dev/\" + \"span\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "qa_model = QAModel(id2word, word2id, emb_matrix)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feb6518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feb6518>>: AttributeError: module 'gast' has no attribute 'Str'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feb6518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feb6518>>: AttributeError: module 'gast' has no attribute 'Str'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feb6518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feb6518>>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feabef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feabef0>>: AttributeError: module 'gast' has no attribute 'Str'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feabef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feabef0>>: AttributeError: module 'gast' has no attribute 'Str'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feabef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feabef0>>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feb6518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feb6518>>: AttributeError: module 'gast' has no attribute 'Str'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feb6518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feb6518>>: AttributeError: module 'gast' has no attribute 'Str'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feb6518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feb6518>>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feabef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feabef0>>: AttributeError: module 'gast' has no attribute 'Str'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feabef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feabef0>>: AttributeError: module 'gast' has no attribute 'Str'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feabef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x7f831feabef0>>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "last dim 300\n",
      "Basic attn keys (?, 300, 300)\n",
      "Basic attn values (?, 300, 30)\n",
      "Basic attn logits (?, 300, 30)\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fbaada0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fbaada0>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fbaada0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fbaada0>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fbaada0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fbaada0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fb9fcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fb9fcf8>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fb9fcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fb9fcf8>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fb9fcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fb9fcf8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fb04748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fb04748>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fb04748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fb04748>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fb04748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831fb04748>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "qa_model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<__main__.QAModel at 0x7f831feb6a58>"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    " # Split by mode\n",
    "if mode == \"train\":\n",
    "    train_dir_path = data_dir + \"Train/\"\n",
    "    file_handler = logging.FileHandler( train_dir_path + \"log.txt\")\n",
    "    logging.getLogger().addHandler(file_handler)\n",
    "\n",
    "    # # Make bestmodel dir if necessary\n",
    "    # if not os.path.exists(bestmodel_dir):\n",
    "    #     os.makedirs(bestmodel_dir)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Load most recent model\n",
    "        initialize_model(sess, qa_model,train_dir_path, expect_exists=False)\n",
    "\n",
    "        # Train\n",
    "        qa_model.train(train_dir_path , sess, train_context_path, train_qn_path, train_ans_path, dev_qn_path, dev_context_path, dev_ans_path)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking for model at ../Data/Train/...\n",
      "There is no saved checkpoint at ../Data/Train/. Creating model with fresh parameters.\n",
      "Num params: 301502\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:root:Number of params: 301502 (retrieval took 1.844465 secs)\n",
      "INFO:root:Beginning training loop...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Refilling batches...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: \"b'115\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-60af5eb89c88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m        \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m        \u001b[0mqa_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir_path\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_context_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_qn_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ans_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_qn_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_context_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_ans_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/sem7/NLPProject/Project/Models/Model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dir, session, train_context_path, train_qn_path, train_ans_path, dev_qn_path, dev_context_path, dev_ans_path)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0;31m# Loop over batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_batch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_context_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_qn_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ans_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscard_long\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                 \u001b[0;31m# Run training iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sem7/NLPProject/Project/Models/data_batcher.py\u001b[0m in \u001b[0;36mget_batch_generator\u001b[0;34m(word2id, context_path, qn_path, ans_path, batch_size, context_len, question_len, discard_long)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m \u001b[0mthose\u001b[0m \u001b[0mexmaples\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mcontext_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqn_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqn_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sem7/NLPProject/Project/Models/data_batcher.py\u001b[0m in \u001b[0;36mrefill_batches\u001b[0;34m(batches, word2id, context_file, qn_file, ans_file, batch_size, context_len, question_len, discard_long)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mcontext_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqn_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqn_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# read the next line from each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mcontext_line\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mqn_line\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mans_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# while you haven't reached the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Convert tokens to word ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sem7/NLPProject/Project/Models/data_batcher.py\u001b[0m in \u001b[0;36mintstr_to_intlist\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mintstr_to_intlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;34m\"\"\"Given a string e.g. '311 9 1334 635 6192 56 639', returns as a list of integers\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sem7/NLPProject/Project/Models/data_batcher.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mintstr_to_intlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;34m\"\"\"Given a string e.g. '311 9 1334 635 6192 56 639', returns as a list of integers\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: \"b'115\""
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "string = \"b'115 114'\"\n",
    "ans = []\n",
    "words = string.split()\n",
    "print(words[0][2:])\n",
    "ans.append(int(words[0][2:]))\n",
    "ans.append(int(words[1][:-1]))\n",
    "print(ans)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "115\n",
      "[115, 114]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "1509c729783193412647cd42bd69a2b55286a15b2066396dbcfcccc0a681516f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}